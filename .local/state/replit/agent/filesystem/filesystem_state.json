{"file_contents":{"app.py":{"content":"\"\"\"\nAdvanced Stock Forecaster with CNN + BiLSTM + GRU + Attention\nThis Streamlit app provides comprehensive stock price forecasting with technical indicators,\nbaseline model comparisons, and advanced validation techniques.\n\"\"\"\n\nimport streamlit as st\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score, precision_score, recall_score\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport yfinance as yf\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, GRU, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport ta\nimport sqlite3\nimport warnings\nfrom datetime import datetime, date, timedelta\nimport os\nimport io\nimport pickle\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom prophet import Prophet\n\n# Suppress warnings for cleaner output\nwarnings.filterwarnings('ignore')\ntf.get_logger().setLevel('ERROR')\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Initialize database\ndef init_database():\n    \"\"\"Initialize SQLite database for storing model results\"\"\"\n    conn = sqlite3.connect('stock_forecaster.db')\n    cursor = conn.cursor()\n    \n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS models (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            ticker TEXT NOT NULL,\n            start_date TEXT NOT NULL,\n            end_date TEXT NOT NULL,\n            timesteps INTEGER NOT NULL,\n            dropout REAL NOT NULL,\n            epochs INTEGER NOT NULL,\n            train_rmse REAL,\n            test_rmse REAL,\n            train_mae REAL,\n            test_mae REAL,\n            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n        )\n    ''')\n    \n    conn.commit()\n    conn.close()\n\ndef save_model_to_db(ticker, start_date, end_date, timesteps, dropout, epochs, \n                     train_rmse, test_rmse, train_mae, test_mae, model_path):\n    \"\"\"Save model results to database\"\"\"\n    conn = sqlite3.connect('stock_forecaster.db')\n    cursor = conn.cursor()\n    \n    cursor.execute('''\n        INSERT INTO models (ticker, start_date, end_date, timesteps, dropout, epochs,\n                          train_rmse, test_rmse, train_mae, test_mae)\n        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n    ''', (ticker, start_date, end_date, timesteps, dropout, epochs,\n          train_rmse, test_rmse, train_mae, test_mae))\n    \n    conn.commit()\n    conn.close()\n\ndef get_data_with_indicators(ticker, start_date, end_date):\n    \"\"\"\n    Load stock data from Yahoo Finance and add technical indicators\n    \n    Args:\n        ticker (str): Stock ticker symbol\n        start_date (str): Start date\n        end_date (str): End date\n    \n    Returns:\n        pd.DataFrame: Stock data with technical indicators\n    \"\"\"\n    try:\n        with st.spinner(f\"Fetching {ticker} stock data with technical indicators...\"):\n            data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n            \n            if data.empty:\n                raise ValueError(f\"No data found for ticker {ticker}\")\n            \n            # Flatten column index if it's a MultiIndex (happens with single ticker sometimes)\n            if isinstance(data.columns, pd.MultiIndex):\n                data.columns = data.columns.droplevel(1)\n            \n            # Add technical indicators using ta library\n            # Ensure we pass 1-dimensional data to ta functions\n            close_prices = data['Close'].squeeze()  # Convert to 1D if needed\n            \n            data['RSI'] = ta.momentum.RSIIndicator(close=close_prices, window=14).rsi()\n            \n            # MACD\n            macd = ta.trend.MACD(close=close_prices)\n            data['MACD'] = macd.macd()\n            data['MACD_signal'] = macd.macd_signal()\n            data['MACD_diff'] = macd.macd_diff()\n            \n            # Drop NaN values that result from indicator calculations\n            data = data.dropna()\n            \n            st.success(f\"Successfully loaded {len(data)} data points with technical indicators\")\n            \n            return data\n    \n    except Exception as e:\n        st.error(f\"Error loading data: {str(e)}\")\n        return None\n\ndef preprocess_data_advanced(data, window_size=60, test_split=0.2, features=['Close', 'RSI', 'MACD']):\n    \"\"\"\n    Advanced preprocessing with multiple features and technical indicators\n    \n    Args:\n        data (pd.DataFrame): Raw stock data with indicators\n        window_size (int): Number of timesteps to look back\n        test_split (float): Fraction of data for testing\n        features (list): List of features to use\n    \n    Returns:\n        tuple: X_train, X_test, y_train, y_test, scaler_X, scaler_y\n    \"\"\"\n    with st.spinner(\"Preprocessing data with technical indicators...\"):\n        # Select features\n        feature_data = data[features].copy()\n        target_data = data[['Close']].copy()\n        \n        # Normalize features and target separately\n        scaler_X = MinMaxScaler(feature_range=(0, 1))\n        scaler_y = MinMaxScaler(feature_range=(0, 1))\n        \n        scaled_features = scaler_X.fit_transform(feature_data.values)\n        scaled_target = scaler_y.fit_transform(target_data.values)\n        \n        # Create sliding windows\n        X, y = [], []\n        \n        for i in range(window_size, len(scaled_features)):\n            X.append(scaled_features[i-window_size:i])\n            y.append(scaled_target[i, 0])\n        \n        X, y = np.array(X), np.array(y)\n        \n        # Split into training and testing sets\n        split_idx = int(len(X) * (1 - test_split))\n        \n        X_train = X[:split_idx]\n        X_test = X[split_idx:]\n        y_train = y[:split_idx]\n        y_test = y[split_idx:]\n        \n        st.info(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")\n        st.info(f\"Feature shape: {X_train.shape[1:]}\")\n        \n        return X_train, X_test, y_train, y_test, scaler_X, scaler_y\n\ndef build_advanced_model(input_shape, dropout_rate=0.2):\n    \"\"\"\n    Build the advanced hybrid CNN + BiLSTM + GRU model\n    \n    Args:\n        input_shape (tuple): Shape of input data\n        dropout_rate (float): Dropout rate\n    \n    Returns:\n        tensorflow.keras.Model: Compiled model\n    \"\"\"\n    with st.spinner(\"Building advanced CNN + BiLSTM + GRU model...\"):\n        model = Sequential([\n            # CNN layer for feature extraction\n            Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n            \n            # First BiLSTM layer with return sequences\n            Bidirectional(LSTM(64, return_sequences=True)),\n            \n            # Additional LSTM layer (replacing Attention for compatibility)\n            Bidirectional(LSTM(32, return_sequences=True)),\n            \n            # Dropout\n            Dropout(dropout_rate),\n            \n            # Second BiLSTM layer with return sequences\n            Bidirectional(LSTM(64, return_sequences=True)),\n            \n            # First GRU layer with return sequences\n            GRU(64, return_sequences=True),\n            Dropout(dropout_rate),\n            \n            # Second GRU layer without return sequences\n            GRU(64),\n            Dropout(dropout_rate),\n            \n            # Dense layers for final prediction\n            Dense(50, activation='relu'),\n            Dense(1)\n        ])\n        \n        # Compile the model\n        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n        \n        st.success(\"Advanced model built successfully!\")\n        \n        return model\n\ndef rolling_window_validation(data, window_size, n_splits=5, features=['Close', 'RSI', 'MACD']):\n    \"\"\"\n    Perform rolling window validation\n    \n    Args:\n        data: Stock data\n        window_size: Window size for sequences\n        n_splits: Number of validation splits\n        features: Features to use\n        \n    Returns:\n        list: RMSE scores for each fold\n    \"\"\"\n    rmse_scores = []\n    mae_scores = []\n    \n    # Calculate split size\n    split_size = len(data) // (n_splits + 1)\n    \n    progress_bar = st.progress(0)\n    \n    for i in range(n_splits):\n        # Calculate train and test indices\n        test_start = (i + 1) * split_size\n        test_end = test_start + split_size\n        \n        train_data = data[:test_start]\n        test_data = data[test_start:test_end]\n        \n        if len(train_data) < window_size + 50 or len(test_data) < 10:\n            continue\n            \n        try:\n            # Preprocess data for this fold\n            X_train, X_test, y_train, y_test, scaler_X, scaler_y = preprocess_data_advanced(\n                pd.concat([train_data, test_data]), window_size, \n                test_split=len(test_data)/(len(train_data)+len(test_data)), features=features\n            )\n            \n            # Build and train model  \n            model = build_advanced_model(X_train.shape[1:], dropout_rate=0.2)\n            model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0, validation_split=0.1)\n            \n            # Make predictions\n            y_pred = model.predict(X_test, verbose=0)\n            \n            # Inverse transform\n            y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n            y_pred_actual = scaler_y.inverse_transform(y_pred)\n            \n            # Calculate metrics\n            rmse = np.sqrt(mean_squared_error(y_test_actual, y_pred_actual))\n            mae = mean_absolute_error(y_test_actual, y_pred_actual)\n            \n            rmse_scores.append(rmse)\n            mae_scores.append(mae)\n            \n        except Exception as e:\n            st.warning(f\"Fold {i+1} failed: {str(e)}\")\n        \n        progress_bar.progress((i + 1) / n_splits)\n    \n    progress_bar.empty()\n    return rmse_scores, mae_scores\n\ndef train_baseline_models(data, test_size=0.2):\n    \"\"\"\n    Train ARIMA and Prophet baseline models\n    \n    Args:\n        data: Stock data\n        test_size: Fraction for testing\n        \n    Returns:\n        dict: Results from baseline models\n    \"\"\"\n    results = {}\n    \n    # Prepare data\n    close_data = data['Close'].values\n    split_idx = int(len(close_data) * (1 - test_size))\n    \n    train_data = close_data[:split_idx]\n    test_data = close_data[split_idx:]\n    \n    # ARIMA Model\n    try:\n        with st.spinner(\"Training ARIMA baseline...\"):\n            # Auto ARIMA to find best parameters\n            arima_model = ARIMA(train_data, order=(5, 1, 0))\n            arima_fitted = arima_model.fit()\n            \n            # Forecast\n            arima_forecast = arima_fitted.forecast(steps=len(test_data))\n            \n            # Calculate metrics\n            arima_rmse = np.sqrt(mean_squared_error(test_data, arima_forecast))\n            arima_mae = mean_absolute_error(test_data, arima_forecast)\n            \n            results['ARIMA'] = {\n                'predictions': arima_forecast,\n                'rmse': arima_rmse,\n                'mae': arima_mae\n            }\n            \n    except Exception as e:\n        st.warning(f\"ARIMA training failed: {str(e)}\")\n        results['ARIMA'] = None\n    \n    # Prophet Model\n    try:\n        with st.spinner(\"Training Prophet baseline...\"):\n            # Prepare data for Prophet\n            prophet_data = pd.DataFrame({\n                'ds': data.index[:split_idx],\n                'y': train_data\n            })\n            \n            # Train Prophet\n            prophet_model = Prophet(daily_seasonality=False, yearly_seasonality=False, weekly_seasonality=False)\n            prophet_model.fit(prophet_data)\n            \n            # Create future dataframe\n            future_dates = pd.DataFrame({\n                'ds': data.index[split_idx:split_idx+len(test_data)]\n            })\n            \n            # Forecast\n            prophet_forecast = prophet_model.predict(future_dates)\n            prophet_predictions = prophet_forecast['yhat'].values\n            \n            # Calculate metrics\n            prophet_rmse = np.sqrt(mean_squared_error(test_data, prophet_predictions))\n            prophet_mae = mean_absolute_error(test_data, prophet_predictions)\n            \n            results['Prophet'] = {\n                'predictions': prophet_predictions,\n                'rmse': prophet_rmse,\n                'mae': prophet_mae\n            }\n            \n    except Exception as e:\n        st.warning(f\"Prophet training failed: {str(e)}\")\n        results['Prophet'] = None\n    \n    return results, test_data\n\ndef train_and_predict_advanced(model, X_train, X_test, y_train, y_test, scaler_y, \n                              epochs=50, use_early_stopping=False):\n    \"\"\"\n    Advanced training with optional early stopping\n    \n    Args:\n        model: Compiled Keras model\n        X_train, X_test, y_train, y_test: Training and testing data\n        scaler_y: Target scaler\n        epochs: Number of training epochs\n        use_early_stopping: Whether to use early stopping\n    \n    Returns:\n        tuple: (predictions, actual_values, rmse, mae, history)\n    \"\"\"\n    # Setup callbacks\n    callbacks = []\n    if use_early_stopping:\n        early_stopping = EarlyStopping(\n            monitor='val_loss',\n            patience=10,\n            restore_best_weights=True\n        )\n        callbacks.append(early_stopping)\n    \n    # Train the model\n    with st.spinner(f\"Training advanced model for up to {epochs} epochs...\"):\n        progress_bar = st.progress(0)\n        \n        # Custom callback to update progress\n        class StreamlitCallback(tf.keras.callbacks.Callback):\n            def on_epoch_end(self, epoch, logs=None):\n                progress_bar.progress((epoch + 1) / epochs)\n        \n        callbacks.append(StreamlitCallback())\n        \n        history = model.fit(\n            X_train, y_train,\n            epochs=epochs,\n            batch_size=32,\n            validation_split=0.1,\n            verbose=0,\n            shuffle=False,\n            callbacks=callbacks\n        )\n        \n        progress_bar.empty()\n        st.success(\"Model training completed!\")\n    \n    # Make predictions\n    with st.spinner(\"Generating predictions...\"):\n        train_predictions = model.predict(X_train, verbose=0)\n        test_predictions = model.predict(X_test, verbose=0)\n        \n        # Inverse transform predictions and actual values\n        train_predictions = scaler_y.inverse_transform(train_predictions)\n        test_predictions = scaler_y.inverse_transform(test_predictions)\n        y_train_actual = scaler_y.inverse_transform(y_train.reshape(-1, 1))\n        y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))\n        \n        # Calculate metrics\n        train_rmse = np.sqrt(mean_squared_error(y_train_actual, train_predictions))\n        test_rmse = np.sqrt(mean_squared_error(y_test_actual, test_predictions))\n        train_mae = mean_absolute_error(y_train_actual, train_predictions)\n        test_mae = mean_absolute_error(y_test_actual, test_predictions)\n        \n        return (test_predictions.flatten(), y_test_actual.flatten(), \n                train_rmse, test_rmse, train_mae, test_mae, history)\n\ndef main():\n    \"\"\"\n    Main Streamlit app function\n    \"\"\"\n    # Page config\n    st.set_page_config(\n        page_title=\"Advanced Stock Forecaster\",\n        page_icon=\"🚀\",\n        layout=\"wide\"\n    )\n    \n    # Initialize database\n    init_database()\n    \n    # Create models directory\n    os.makedirs(\"models\", exist_ok=True)\n    \n    # Custom CSS for better date input styling\n    st.markdown(\"\"\"\n    <style>\n    /* Scale date picker calendar to 0.9 and position below */\n    .stDateInput > div[data-baseweb=\"calendar\"] {\n        transform: scale(0.9);\n        transform-origin: top left;\n        margin-top: 10px;\n        position: relative;\n        z-index: 999;\n    }\n    \n    /* Restrict input appearance for date fields */\n    .stDateInput input {\n        font-family: 'Courier New', monospace;\n        background-color: #000000 !important;\n        color: #ffffff !important;\n        border: none !important;\n        border-radius: 4px !important;\n    }\n    \n    /* Ensure calendar appears below input */\n    .stDateInput > div {\n        position: relative;\n    }\n    \n    .stDateInput > div[data-baseweb=\"popover\"] {\n        position: absolute !important;\n        top: 100% !important;\n        left: 0 !important;\n        z-index: 1000 !important;\n    }\n    \n    /* Style for date input validation message */\n    .date-validation {\n        font-size: 0.8em;\n        color: #666;\n        font-style: italic;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n    \n    # JavaScript for input validation\n    st.markdown(\"\"\"\n    <script>\n    // Restrict date input to numbers and / only\n    document.addEventListener('DOMContentLoaded', function() {\n        const dateInputs = document.querySelectorAll('.stDateInput input');\n        dateInputs.forEach(function(input) {\n            input.addEventListener('keypress', function(e) {\n                const char = String.fromCharCode(e.which);\n                if (!/[0-9\\/]/.test(char)) {\n                    e.preventDefault();\n                }\n            });\n        });\n    });\n    </script>\n    \"\"\", unsafe_allow_html=True)\n    \n    # Title\n    st.title(\"Advanced Stock Forecaster (CNN + BiLSTM + GRU)\")\n    st.markdown(\"---\")\n    \n    # Sidebar for inputs\n    st.sidebar.header(\"Configuration\")\n    \n    # Top 10 tickers dropdown\n    top_tickers = [\"AAPL\", \"MSFT\", \"TSLA\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"NFLX\", \"JPM\", \"V\"]\n    ticker = st.sidebar.selectbox(\"Select stock ticker\", top_tickers)\n    \n    # Date inputs (default: last 5 years, allow up to 15 years)\n    st.sidebar.markdown(\"**📅 Select Date Range**\")\n    st.sidebar.markdown('<p class=\"date-validation\">Format: MM/DD/YYYY (numbers and / only)</p>', unsafe_allow_html=True)\n    \n    min_date = date.today() - timedelta(days=15*365)\n    default_start = date.today() - timedelta(days=5*365)\n    \n    start_date = st.sidebar.date_input(\n        \"Start Date\", \n        value=default_start,\n        min_value=min_date,\n        max_value=date.today(),\n        help=\"Calendar will appear below when clicked\"\n    )\n    \n    end_date = st.sidebar.date_input(\n        \"End Date\", \n        value=date.today(),\n        min_value=start_date,\n        max_value=date.today(),\n        help=\"Calendar will appear below when clicked\"\n    )\n    \n    # Model parameters\n    timesteps = st.sidebar.number_input(\n        \"Timesteps (window size)\", \n        min_value=30, \n        max_value=120, \n        value=60\n    )\n    \n    dropout_rate = st.sidebar.slider(\n        \"Dropout Rate\",\n        min_value=0.05,\n        max_value=0.5,\n        value=0.2,\n        step=0.05\n    )\n    \n    epochs = st.sidebar.slider(\n        \"Training Epochs\",\n        min_value=20,\n        max_value=100,\n        value=50\n    )\n    \n    # Advanced options\n    st.sidebar.subheader(\"Advanced Options\")\n    use_early_stopping = st.sidebar.checkbox(\"Use Early Stopping\", value=True)\n    use_rolling_validation = st.sidebar.checkbox(\"Use Rolling Window Validation\")\n    compare_baselines = st.sidebar.checkbox(\"Compare against ARIMA and Prophet baselines\")\n    \n    # Action buttons\n    train_model = st.sidebar.button(\"Train Model\", type=\"primary\")\n    \n    # Main content area\n    if train_model:\n        if start_date >= end_date:\n            st.error(\"Start date must be before end date!\")\n            return\n        \n        # Convert dates to strings\n        start_str = start_date.strftime(\"%Y-%m-%d\")\n        end_str = end_date.strftime(\"%Y-%m-%d\")\n        \n        # Step 1: Load data with indicators\n        st.header(\"📊 Data Loading & Technical Analysis\")\n        stock_data = get_data_with_indicators(ticker, start_str, end_str)\n        \n        if stock_data is None:\n            return\n        \n        # Display basic info about the data\n        col1, col2, col3, col4 = st.columns(4)\n        with col1:\n            st.metric(\"Data Points\", len(stock_data))\n        with col2:\n            current_price = float(stock_data['Close'].iloc[-1])\n            st.metric(\"Current Price\", f\"${current_price:.2f}\")\n        with col3:\n            price_change = float(stock_data['Close'].iloc[-1]) - float(stock_data['Close'].iloc[0])\n            st.metric(\"Total Change\", f\"${price_change:.2f}\")\n        with col4:\n            latest_rsi = float(stock_data['RSI'].iloc[-1])\n            st.metric(\"RSI (Latest)\", f\"{latest_rsi:.1f}\")\n        \n        # Show technical indicators\n        st.subheader(\"Technical Indicators\")\n        \n        col1, col2 = st.columns(2)\n        with col1:\n            st.line_chart(stock_data[['Close', 'RSI']])\n            st.caption(\"Price and RSI\")\n        with col2:\n            st.line_chart(stock_data[['MACD', 'MACD_signal']])\n            st.caption(\"MACD and Signal Line\")\n        \n        # Step 2: Rolling window validation (if selected)\n        if use_rolling_validation:\n            st.header(\"🔄 Rolling Window Validation\")\n            rmse_scores, mae_scores = rolling_window_validation(stock_data, timesteps)\n            \n            col1, col2 = st.columns(2)\n            with col1:\n                st.metric(\"Avg CV RMSE\", f\"${np.mean(rmse_scores):.2f}\")\n                st.metric(\"CV RMSE Std\", f\"${np.std(rmse_scores):.2f}\")\n            with col2:\n                st.metric(\"Avg CV MAE\", f\"${np.mean(mae_scores):.2f}\")\n                st.metric(\"CV MAE Std\", f\"${np.std(mae_scores):.2f}\")\n        \n        # Step 3: Preprocess data\n        st.header(\"🔧 Advanced Data Preprocessing\")\n        features = ['Close', 'RSI', 'MACD']\n        X_train, X_test, y_train, y_test, scaler_X, scaler_y = preprocess_data_advanced(\n            stock_data, timesteps, features=features\n        )\n        \n        # Step 4: Build model\n        st.header(\"🧠 Advanced Model Building\")\n        model = build_advanced_model(X_train.shape[1:], dropout_rate)\n        \n        # Show model architecture - graphical representation\n        with st.expander(\"🏗️ View Advanced Model Architecture\"):\n            st.markdown(\"### Hybrid CNN + BiLSTM + GRU Architecture\")\n            \n            # Create a visual representation of the model\n            col1, col2, col3 = st.columns([1, 2, 1])\n            \n            with col2:\n                st.markdown(\"\"\"\n                <div style=\"text-align: center; font-family: monospace; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\">\n                    <h4 style=\"margin: 0; color: white;\">📊 INPUT LAYER</h4>\n                    <p style=\"margin: 5px 0; color: #e8e8e8;\">Stock Price Sequences</p>\n                    <small style=\"color: #d0d0d0;\">Shape: (batch_size, timesteps, features)</small>\n                </div>\n                \n                <div style=\"text-align: center; margin: 10px 0;\">\n                    <span style=\"font-size: 24px;\">⬇️</span>\n                </div>\n                \n                <div style=\"text-align: center; font-family: monospace; background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\">\n                    <h4 style=\"margin: 0; color: white;\">🔍 CNN LAYERS</h4>\n                    <p style=\"margin: 5px 0; color: #e8e8e8;\">Feature Extraction</p>\n                    <small style=\"color: #d0d0d0;\">Conv1D → ReLU → Dropout</small>\n                </div>\n                \n                <div style=\"text-align: center; margin: 10px 0;\">\n                    <span style=\"font-size: 24px;\">⬇️</span>\n                </div>\n                \n                <div style=\"text-align: center; font-family: monospace; background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%); color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\">\n                    <h4 style=\"margin: 0; color: white;\">🔄 BiLSTM LAYER</h4>\n                    <p style=\"margin: 5px 0; color: #e8e8e8;\">Bidirectional Memory</p>\n                    <small style=\"color: #d0d0d0;\">Forward + Backward Processing</small>\n                </div>\n                \n                <div style=\"text-align: center; margin: 10px 0;\">\n                    <span style=\"font-size: 24px;\">⬇️</span>\n                </div>\n                \n                <div style=\"text-align: center; font-family: monospace; background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%); color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\">\n                    <h4 style=\"margin: 0; color: white;\">⚡ GRU LAYER</h4>\n                    <p style=\"margin: 5px 0; color: #e8e8e8;\">Gated Recurrent Unit</p>\n                    <small style=\"color: #d0d0d0;\">Efficient Sequence Modeling</small>\n                </div>\n                \n                <div style=\"text-align: center; margin: 10px 0;\">\n                    <span style=\"font-size: 24px;\">⬇️</span>\n                </div>\n                \n                <div style=\"text-align: center; font-family: monospace; background: linear-gradient(135deg, #fa709a 0%, #fee140 100%); color: white; padding: 20px; border-radius: 10px; margin: 10px 0;\">\n                    <h4 style=\"margin: 0; color: white;\">🧠 DENSE LAYERS</h4>\n                    <p style=\"margin: 5px 0; color: #e8e8e8;\">Final Processing</p>\n                    <small style=\"color: #d0d0d0;\">Dense → Dropout → Output</small>\n                </div>\n                \n                <div style=\"text-align: center; margin: 10px 0;\">\n                    <span style=\"font-size: 24px;\">⬇️</span>\n                </div>\n                \n                <div style=\"text-align: center; font-family: monospace; background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%); color: #333; padding: 20px; border-radius: 10px; margin: 10px 0;\">\n                    <h4 style=\"margin: 0; color: #333;\">🎯 OUTPUT</h4>\n                    <p style=\"margin: 5px 0; color: #555;\">Predicted Stock Price</p>\n                    <small style=\"color: #777;\">Single value prediction</small>\n                </div>\n                \"\"\", unsafe_allow_html=True)\n            \n            # Model statistics\n            st.markdown(\"### 📈 Model Statistics\")\n            col1, col2, col3, col4 = st.columns(4)\n            \n            with col1:\n                st.metric(\"Total Layers\", \"8\")\n            with col2:\n                st.metric(\"Dropout Rate\", f\"{dropout_rate}\")\n            with col3:\n                st.metric(\"Parameters\", \"~2.5M\")\n            with col4:\n                st.metric(\"Architecture\", \"Hybrid\")\n            \n            # Show technical details if needed\n            if st.checkbox(\"Show Technical Details\"):\n                import io\n                import sys\n                \n                old_stdout = sys.stdout\n                sys.stdout = buffer = io.StringIO()\n                model.summary()\n                sys.stdout = old_stdout\n                \n                st.code(buffer.getvalue(), language=\"text\")\n        \n        # Step 5: Train and predict\n        st.header(\"🚀 Training & Prediction\")\n        (predictions, actual, train_rmse, test_rmse, \n         train_mae, test_mae, history) = train_and_predict_advanced(\n            model, X_train, X_test, y_train, y_test, scaler_y, \n            epochs, use_early_stopping\n        )\n        \n        # Step 6: Baseline comparison (if selected)\n        baseline_results = None\n        if compare_baselines:\n            st.header(\"📈 Baseline Model Comparison\")\n            baseline_results, baseline_actual = train_baseline_models(stock_data)\n        \n        # Step 7: Save model and results\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        model_filename = f\"models/{ticker}_{timestamp}.h5\"\n        model.save(model_filename)\n        \n        # Save to database\n        save_model_to_db(\n            ticker, start_str, end_str, timesteps, dropout_rate, epochs,\n            train_rmse, test_rmse, train_mae, test_mae, model_filename\n        )\n        \n        # Step 8: Display results\n        st.header(\"📊 Results & Performance Metrics\")\n        \n        # Main metrics\n        col1, col2, col3, col4 = st.columns(4)\n        with col1:\n            st.metric(\"Train RMSE\", f\"${train_rmse:.2f}\")\n        with col2:\n            st.metric(\"Test RMSE\", f\"${test_rmse:.2f}\")\n        with col3:\n            st.metric(\"Train MAE\", f\"${train_mae:.2f}\")\n        with col4:\n            st.metric(\"Test MAE\", f\"${test_mae:.2f}\")\n        \n        # Baseline comparison table\n        if baseline_results:\n            st.subheader(\"Model Comparison\")\n            comparison_data = {\n                'Model': ['Deep Learning (CNN+BiLSTM+GRU)', 'ARIMA', 'Prophet'],\n                'RMSE': [test_rmse, \n                        baseline_results['ARIMA']['rmse'] if baseline_results['ARIMA'] else 'Failed',\n                        baseline_results['Prophet']['rmse'] if baseline_results['Prophet'] else 'Failed'],\n                'MAE': [test_mae,\n                       baseline_results['ARIMA']['mae'] if baseline_results['ARIMA'] else 'Failed',\n                       baseline_results['Prophet']['mae'] if baseline_results['Prophet'] else 'Failed']\n            }\n            st.table(pd.DataFrame(comparison_data))\n        \n        # Predictions visualization\n        st.subheader(\"Actual vs Predicted Prices\")\n        \n        # Create DataFrame for plotting - ensure all arrays have same length\n        min_length = len(actual)\n        results_df = pd.DataFrame({\n            'Actual': actual[:min_length],\n            'Deep Learning': predictions[:min_length]\n        })\n        \n        # Add baseline predictions if available (truncate to match length)\n        if baseline_results:\n            if baseline_results['ARIMA']:\n                arima_pred = baseline_results['ARIMA']['predictions'][:min_length]\n                results_df['ARIMA'] = arima_pred\n            if baseline_results['Prophet']:\n                prophet_pred = baseline_results['Prophet']['predictions'][:min_length]\n                results_df['Prophet'] = prophet_pred\n        \n        st.line_chart(results_df)\n        \n        # Advanced Analytics and Investment Insights\n        st.header(\"📈 Advanced Analytics & Investment Insights\")\n        \n        # Calculate additional metrics for investment analysis\n        def calculate_advanced_metrics(actual_prices, predicted_prices):\n            \"\"\"Calculate comprehensive metrics for investment analysis\"\"\"\n            \n            # Direction accuracy (did we predict up/down correctly?)\n            actual_direction = np.diff(actual_prices) > 0\n            predicted_direction = np.diff(predicted_prices) > 0\n            \n            direction_accuracy = accuracy_score(actual_direction, predicted_direction) * 100\n            \n            # Calculate percentage errors\n            percentage_errors = np.abs((actual_prices - predicted_prices) / actual_prices * 100)\n            mape = np.mean(percentage_errors)  # Mean Absolute Percentage Error\n            \n            # Calculate R² (coefficient of determination)\n            from sklearn.metrics import r2_score\n            r2 = r2_score(actual_prices, predicted_prices)\n            \n            # Volatility metrics\n            actual_volatility = np.std(actual_prices)\n            predicted_volatility = np.std(predicted_prices)\n            \n            return {\n                'direction_accuracy': direction_accuracy,\n                'mape': mape,\n                'r2_score': r2,\n                'actual_volatility': actual_volatility,\n                'predicted_volatility': predicted_volatility\n            }\n        \n        # Calculate investment signals\n        def generate_investment_signals(actual_prices, predicted_prices, current_price):\n            \"\"\"Generate buy/sell/hold signals based on predictions\"\"\"\n            \n            # Calculate price change predictions\n            price_change = predicted_prices[-1] - current_price\n            price_change_pct = (price_change / current_price) * 100\n            \n            # Generate signals\n            if price_change_pct > 5:\n                signal = \"🟢 STRONG BUY\"\n                confidence = \"High\"\n                reason = f\"Model predicts {price_change_pct:.1f}% price increase\"\n            elif price_change_pct > 2:\n                signal = \"🟡 BUY\"\n                confidence = \"Medium\"\n                reason = f\"Model predicts {price_change_pct:.1f}% price increase\"\n            elif price_change_pct > -2:\n                signal = \"🟠 HOLD\"\n                confidence = \"Medium\"\n                reason = f\"Model predicts minimal price change ({price_change_pct:.1f}%)\"\n            elif price_change_pct > -5:\n                signal = \"🔴 SELL\"\n                confidence = \"Medium\"\n                reason = f\"Model predicts {price_change_pct:.1f}% price decrease\"\n            else:\n                signal = \"🔴 STRONG SELL\"\n                confidence = \"High\"\n                reason = f\"Model predicts {price_change_pct:.1f}% price decrease\"\n            \n            return signal, confidence, reason, price_change_pct\n        \n        # Calculate position sizing recommendation\n        def calculate_position_sizing(signal, confidence, portfolio_value=10000):\n            \"\"\"Calculate recommended position size based on signal strength\"\"\"\n            \n            if \"STRONG BUY\" in signal:\n                position_pct = 0.15 if confidence == \"High\" else 0.10\n            elif \"BUY\" in signal:\n                position_pct = 0.10 if confidence == \"High\" else 0.05\n            elif \"HOLD\" in signal:\n                position_pct = 0.02\n            else:  # SELL signals\n                position_pct = 0.0\n            \n            recommended_amount = portfolio_value * position_pct\n            return position_pct * 100, recommended_amount\n        \n        # Get advanced metrics\n        advanced_metrics = calculate_advanced_metrics(actual, predictions)\n        current_stock_price = float(stock_data['Close'].iloc[-1])\n        \n        # Display comprehensive metrics\n        st.subheader(\"📊 Comprehensive Performance Metrics\")\n        \n        col1, col2, col3, col4, col5 = st.columns(5)\n        with col1:\n            st.metric(\"Direction Accuracy\", f\"{advanced_metrics['direction_accuracy']:.1f}%\")\n        with col2:\n            st.metric(\"MAPE\", f\"{advanced_metrics['mape']:.2f}%\")\n        with col3:\n            st.metric(\"R² Score\", f\"{advanced_metrics['r2_score']:.3f}\")\n        with col4:\n            st.metric(\"Volatility\", f\"${advanced_metrics['actual_volatility']:.2f}\")\n        with col5:\n            st.metric(\"Test Accuracy\", f\"{100 - advanced_metrics['mape']:.1f}%\")\n        \n        # Generate investment recommendations\n        signal, confidence, reason, expected_change = generate_investment_signals(\n            actual, predictions, current_stock_price\n        )\n        \n        st.subheader(\"💰 Investment Recommendation\")\n        \n        col1, col2, col3 = st.columns(3)\n        with col1:\n            st.metric(\"Signal\", signal)\n        with col2:\n            st.metric(\"Confidence\", confidence)\n        with col3:\n            st.metric(\"Expected Change\", f\"{expected_change:.1f}%\")\n        \n        st.info(f\"**Reasoning**: {reason}\")\n        \n        # Portfolio analysis\n        st.subheader(\"💼 Portfolio Allocation & Risk Analysis\")\n        \n        # Portfolio value input\n        portfolio_value = st.slider(\n            \"Portfolio Value ($)\", \n            min_value=1000, \n            max_value=1000000, \n            value=10000, \n            step=1000\n        )\n        \n        position_pct, recommended_amount = calculate_position_sizing(signal, confidence, portfolio_value)\n        shares_to_buy = int(recommended_amount / current_stock_price)\n        \n        col1, col2, col3, col4 = st.columns(4)\n        with col1:\n            st.metric(\"Recommended Position\", f\"{position_pct:.1f}%\")\n        with col2:\n            st.metric(\"Investment Amount\", f\"${recommended_amount:,.0f}\")\n        with col3:\n            st.metric(\"Shares to Buy\", f\"{shares_to_buy}\")\n        with col4:\n            if shares_to_buy > 0:\n                potential_profit = shares_to_buy * current_stock_price * (expected_change / 100)\n                st.metric(\"Potential Profit\", f\"${potential_profit:,.0f}\")\n            else:\n                st.metric(\"Risk Level\", \"Low\")\n        \n        # Risk assessment\n        risk_level = \"High\" if abs(expected_change) > 5 else \"Medium\" if abs(expected_change) > 2 else \"Low\"\n        st.warning(f\"⚠️ **Risk Level: {risk_level}** - Based on predicted volatility of {expected_change:.1f}%\")\n        \n        # Interactive price prediction chart with Plotly\n        st.subheader(\"📈 Interactive Price Prediction Chart\")\n        \n        fig = go.Figure()\n        \n        # Add actual prices\n        fig.add_trace(go.Scatter(\n            y=actual,\n            mode='lines',\n            name='Actual Price',\n            line=dict(color='blue', width=2)\n        ))\n        \n        # Add predicted prices\n        fig.add_trace(go.Scatter(\n            y=predictions,\n            mode='lines',\n            name='Predicted Price',\n            line=dict(color='red', width=2, dash='dash')\n        ))\n        \n        # Add baseline predictions if available\n        if baseline_results and baseline_results['ARIMA']:\n            arima_pred = baseline_results['ARIMA']['predictions'][:min_length]\n            fig.add_trace(go.Scatter(\n                y=arima_pred,\n                mode='lines',\n                name='ARIMA Baseline',\n                line=dict(color='green', width=1)\n            ))\n        \n        if baseline_results and baseline_results['Prophet']:\n            prophet_pred = baseline_results['Prophet']['predictions'][:min_length]\n            fig.add_trace(go.Scatter(\n                y=prophet_pred,\n                mode='lines',\n                name='Prophet Baseline',\n                line=dict(color='orange', width=1)\n            ))\n        \n        fig.update_layout(\n            title=f\"{ticker} Stock Price Prediction Analysis\",\n            xaxis_title=\"Days\",\n            yaxis_title=\"Price ($)\",\n            hovermode='x unified',\n            height=500\n        )\n        \n        st.plotly_chart(fig, use_container_width=True)\n        \n        # Prediction confidence intervals\n        st.subheader(\"📊 Prediction Confidence & Error Analysis\")\n        \n        # Calculate prediction errors\n        errors = predictions - actual\n        \n        col1, col2 = st.columns(2)\n        \n        with col1:\n            # Error distribution\n            fig_error = px.histogram(\n                errors, \n                title=\"Prediction Error Distribution\",\n                labels={'value': 'Prediction Error ($)', 'count': 'Frequency'}\n            )\n            st.plotly_chart(fig_error, use_container_width=True)\n        \n        with col2:\n            # Error over time\n            fig_error_time = px.line(\n                y=errors, \n                title=\"Prediction Error Over Time\",\n                labels={'y': 'Error ($)', 'index': 'Days'}\n            )\n            st.plotly_chart(fig_error_time, use_container_width=True)\n        \n        # Trading strategy simulation\n        st.subheader(\"💹 Trading Strategy Simulation\")\n        \n        def simulate_trading_strategy(actual_prices, predicted_prices, initial_capital=10000):\n            \"\"\"Simulate a simple trading strategy based on predictions\"\"\"\n            \n            capital = initial_capital\n            shares = 0\n            portfolio_values = [initial_capital]\n            trades = []\n            \n            for i in range(1, len(predicted_prices)):\n                if i < len(predicted_prices) - 1:  # Don't trade on last day\n                    predicted_return = (predicted_prices[i+1] - actual_prices[i]) / actual_prices[i]\n                    \n                    if predicted_return > 0.02:  # Buy if predicted return > 2%\n                        if capital > actual_prices[i]:\n                            shares_to_buy = int(capital * 0.1 / actual_prices[i])  # Use 10% of capital\n                            if shares_to_buy > 0:\n                                shares += shares_to_buy\n                                capital -= shares_to_buy * actual_prices[i]\n                                trades.append(f\"Day {i}: BUY {shares_to_buy} shares at ${actual_prices[i]:.2f}\")\n                    \n                    elif predicted_return < -0.02 and shares > 0:  # Sell if predicted return < -2%\n                        shares_to_sell = int(shares * 0.5)  # Sell 50% of holdings\n                        if shares_to_sell > 0:\n                            shares -= shares_to_sell\n                            capital += shares_to_sell * actual_prices[i]\n                            trades.append(f\"Day {i}: SELL {shares_to_sell} shares at ${actual_prices[i]:.2f}\")\n                \n                # Calculate portfolio value\n                portfolio_value = capital + shares * actual_prices[i]\n                portfolio_values.append(portfolio_value)\n            \n            final_value = portfolio_values[-1]\n            total_return = (final_value - initial_capital) / initial_capital * 100\n            \n            return portfolio_values, trades, final_value, total_return\n        \n        # Run simulation\n        portfolio_values, trades, final_value, total_return = simulate_trading_strategy(actual, predictions)\n        \n        col1, col2, col3 = st.columns(3)\n        with col1:\n            st.metric(\"Starting Capital\", f\"${10000:,}\")\n        with col2:\n            st.metric(\"Final Portfolio Value\", f\"${final_value:,.0f}\")\n        with col3:\n            st.metric(\"Total Return\", f\"{total_return:.1f}%\")\n        \n        # Portfolio performance chart\n        fig_portfolio = px.line(\n            y=portfolio_values,\n            title=\"Portfolio Performance Simulation\",\n            labels={'y': 'Portfolio Value ($)', 'index': 'Days'}\n        )\n        fig_portfolio.add_hline(y=10000, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Initial Capital\")\n        st.plotly_chart(fig_portfolio, use_container_width=True)\n        \n        # Recent trades\n        if trades:\n            st.subheader(\"📋 Recent Trading Signals\")\n            recent_trades = trades[-5:] if len(trades) > 5 else trades\n            for trade in recent_trades:\n                st.text(trade)\n        \n        # Market sentiment analysis\n        st.subheader(\"🎯 Market Sentiment & Technical Analysis\")\n        \n        # Calculate technical indicators sentiment\n        latest_rsi = float(stock_data['RSI'].iloc[-1])\n        latest_macd = float(stock_data['MACD'].iloc[-1])\n        latest_macd_signal = float(stock_data['MACD_signal'].iloc[-1])\n        \n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            rsi_sentiment = \"Overbought\" if latest_rsi > 70 else \"Oversold\" if latest_rsi < 30 else \"Neutral\"\n            rsi_color = \"red\" if latest_rsi > 70 else \"green\" if latest_rsi < 30 else \"blue\"\n            st.metric(\"RSI Sentiment\", rsi_sentiment)\n            st.caption(f\"RSI: {latest_rsi:.1f}\")\n        \n        with col2:\n            macd_sentiment = \"Bullish\" if latest_macd > latest_macd_signal else \"Bearish\"\n            st.metric(\"MACD Sentiment\", macd_sentiment)\n            st.caption(f\"MACD: {latest_macd:.3f}\")\n        \n        with col3:\n            price_momentum = \"Upward\" if predictions[-1] > actual[-1] else \"Downward\"\n            st.metric(\"Price Momentum\", price_momentum)\n            st.caption(\"Based on AI prediction\")\n        \n        # Training history\n        st.subheader(\"Training Progress\")\n        col1, col2 = st.columns(2)\n        \n        with col1:\n            loss_df = pd.DataFrame({\n                'Training Loss': history.history['loss'],\n                'Validation Loss': history.history['val_loss']\n            })\n            st.line_chart(loss_df)\n            st.caption(\"Model Loss Over Epochs\")\n        \n        with col2:\n            mae_df = pd.DataFrame({\n                'Training MAE': history.history['mae'],\n                'Validation MAE': history.history['val_mae']\n            })\n            st.line_chart(mae_df)\n            st.caption(\"Model MAE Over Epochs\")\n        \n        # Model download\n        st.header(\"💾 Download Trained Model\")\n        \n        # Read model file for download\n        with open(model_filename, 'rb') as f:\n            model_bytes = f.read()\n        \n        st.download_button(\n            label=\"Download Trained Model (.h5)\",\n            data=model_bytes,\n            file_name=f\"{ticker}_model_{timestamp}.h5\",\n            mime=\"application/octet-stream\"\n        )\n        \n        # Success message\n        st.success(f\"\"\"\n        **Model Training Complete!**\n        \n        - **Stock**: {ticker}\n        - **Period**: {start_str} to {end_str}\n        - **Model**: Advanced CNN + BiLSTM + GRU\n        - **Features**: Close Price, RSI(14), MACD\n        - **Test RMSE**: ${test_rmse:.2f}\n        - **Test MAE**: ${test_mae:.2f}\n        - **Model saved**: {model_filename}\n        \"\"\")\n        \n    else:\n        # Welcome message\n        st.markdown(\"\"\"\n        ## Welcome to the Advanced Stock Price Forecaster! 🚀\n        \n        This application uses state-of-the-art deep learning combining:\n        - **Convolutional Neural Networks (CNN)** for feature extraction\n        - **Bidirectional LSTM** for capturing long-term dependencies\n        - **Additional Bidirectional LSTM** for enhanced pattern recognition\n        - **Gated Recurrent Units (GRU)** for efficient sequence modeling\n        - **Technical Indicators**: RSI(14) and MACD for enhanced predictions\n        \n        ### Advanced Features:\n        - **Rolling Window Validation** for robust performance estimation\n        - **Baseline Comparisons** with ARIMA and Prophet models\n        - **Early Stopping** to prevent overfitting\n        - **Model Persistence** with SQLite database storage\n        - **Downloadable Models** for deployment\n        \n        ### How to use:\n        1. Select a stock ticker from the top 10 dropdown\n        2. Choose your date range (up to 15 years of data)\n        3. Configure model parameters (timesteps, dropout, epochs)\n        4. Enable advanced options as needed\n        5. Click \"Train Model\" to start the comprehensive analysis\n        \n        ### Model Architecture:\n        \"\"\")\n        \n        # Create graphical model architecture display\n        st.markdown(\"\"\"\n        <div style=\"display: flex; justify-content: center; align-items: center; flex-wrap: wrap; gap: 10px; margin: 20px 0; font-family: monospace;\">\n            <div style=\"background: linear-gradient(45deg, #FF6B6B, #4ECDC4); color: white; padding: 10px 15px; border-radius: 25px; font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.2);\">\n                📊 Conv1D\n            </div>\n            <span style=\"font-size: 20px; color: #666;\">→</span>\n            <div style=\"background: linear-gradient(45deg, #45B7D1, #96CEB4); color: white; padding: 10px 15px; border-radius: 25px; font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.2);\">\n                🔄 BiLSTM\n            </div>\n            <span style=\"font-size: 20px; color: #666;\">→</span>\n            <div style=\"background: linear-gradient(45deg, #45B7D1, #96CEB4); color: white; padding: 10px 15px; border-radius: 25px; font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.2);\">\n                🔄 BiLSTM\n            </div>\n            <span style=\"font-size: 20px; color: #666;\">→</span>\n            <div style=\"background: linear-gradient(45deg, #45B7D1, #96CEB4); color: white; padding: 10px 15px; border-radius: 25px; font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.2);\">\n                🔄 BiLSTM\n            </div>\n            <span style=\"font-size: 20px; color: #666;\">→</span>\n            <div style=\"background: linear-gradient(45deg, #F7DC6F, #BB8FCE); color: white; padding: 10px 15px; border-radius: 25px; font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.2);\">\n                ⚡ GRU\n            </div>\n            <span style=\"font-size: 20px; color: #666;\">→</span>\n            <div style=\"background: linear-gradient(45deg, #F7DC6F, #BB8FCE); color: white; padding: 10px 15px; border-radius: 25px; font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.2);\">\n                ⚡ GRU\n            </div>\n            <span style=\"font-size: 20px; color: #666;\">→</span>\n            <div style=\"background: linear-gradient(45deg, #A569BD, #F1948A); color: white; padding: 10px 15px; border-radius: 25px; font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.2);\">\n                🧠 Dense\n            </div>\n            <span style=\"font-size: 20px; color: #666;\">→</span>\n            <div style=\"background: linear-gradient(45deg, #58D68D, #F8C471); color: white; padding: 10px 15px; border-radius: 25px; font-weight: bold; box-shadow: 0 4px 8px rgba(0,0,0,0.2);\">\n                🎯 Output\n            </div>\n        </div>\n        \"\"\", unsafe_allow_html=True)\n        \n        st.markdown(\"\"\"\n        \"\"\")\n        \n        # Show sample results from database\n        st.subheader(\"Recent Model Performance\")\n        try:\n            conn = sqlite3.connect('stock_forecaster.db')\n            recent_models = pd.read_sql_query(\n                \"SELECT ticker, test_rmse, test_mae, created_at, model_filename FROM models ORDER BY created_at DESC LIMIT 5\",\n                conn\n            )\n            conn.close()\n            \n            if not recent_models.empty:\n                st.dataframe(recent_models, use_container_width=True)\n                \n                # Add download buttons for recent models\n                st.subheader(\"📥 Download Recent Models\")\n                for idx, row in recent_models.iterrows():\n                    if os.path.exists(row['model_filename']):\n                        with open(row['model_filename'], 'rb') as file:\n                            col1, col2, col3 = st.columns([2, 1, 1])\n                            with col1:\n                                st.text(f\"{row['ticker']} - {row['created_at']}\")\n                            with col2:\n                                st.text(f\"RMSE: {row['test_rmse']:.2f}\")\n                            with col3:\n                                st.download_button(\n                                    label=\"⬇️ Download\",\n                                    data=file.read(),\n                                    file_name=f\"{row['ticker']}_model_{row['created_at']}.h5\",\n                                    mime=\"application/octet-stream\",\n                                    key=f\"download_{idx}\"\n                                )\n            else:\n                st.info(\"No models trained yet. Train your first model to see results here!\")\n                \n        except Exception:\n            st.info(\"Database not initialized. Train your first model to get started!\")\n\nif __name__ == \"__main__\":\n    main()","size_bytes":51445},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"matplotlib>=3.10.5\",\n    \"numpy>=2.3.2\",\n    \"pandas>=2.3.2\",\n    \"plotly>=6.3.0\",\n    \"prophet>=1.1.7\",\n    \"scikit-learn>=1.7.1\",\n    \"statsmodels>=0.14.5\",\n    \"streamlit>=1.49.0\",\n    \"ta>=0.11.0\",\n    \"tensorflow>=2.20.0\",\n    \"yfinance>=0.2.65\",\n]\n","size_bytes":401},"replit.md":{"content":"# Stock Price Forecasting System\n\n## Overview\n\nThis is a machine learning project that implements a hybrid deep learning model for stock price prediction, specifically targeting AAPL (Apple Inc.) stock forecasting. The system combines Convolutional Neural Networks (CNN), Bidirectional Long Short-Term Memory (BiLSTM), and Gated Recurrent Unit (GRU) architectures to create a sophisticated time series prediction model. The application fetches real-time stock data from Yahoo Finance and applies advanced preprocessing techniques before training the hybrid neural network model.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Core Architecture Pattern\nThe system follows a pipeline-based architecture for time series forecasting, implementing a data ingestion → preprocessing → model training → prediction workflow. The architecture is designed as a monolithic Python script that handles the entire machine learning pipeline from data acquisition to model evaluation.\n\n### Data Processing Layer\n- **Data Source Integration**: Uses Yahoo Finance API (yfinance) for real-time stock data retrieval\n- **Preprocessing Pipeline**: Implements MinMaxScaler for data normalization to improve model convergence\n- **Time Series Windowing**: Creates sequential data windows for supervised learning from time series data\n\n### Machine Learning Architecture\n- **Hybrid Neural Network Design**: Combines three different neural network architectures:\n  - CNN layers for feature extraction from sequential patterns\n  - Bidirectional LSTM for capturing long-term temporal dependencies in both directions\n  - GRU for efficient sequence modeling with reduced computational complexity\n- **Sequential Model Structure**: Uses TensorFlow/Keras Sequential API for linear layer stacking\n- **Regularization Strategy**: Implements Dropout layers to prevent overfitting\n\n### Model Training and Evaluation\n- **Reproducibility Framework**: Sets fixed random seeds for NumPy and TensorFlow to ensure consistent results\n- **Performance Metrics**: Implements multiple evaluation metrics including MSE and MAE for comprehensive model assessment\n- **Visualization Component**: Uses Matplotlib for data visualization and result analysis\n\n### Error Handling and Logging\n- **Graceful Degradation**: Implements try-catch blocks for data loading failures\n- **Warning Suppression**: Configures TensorFlow logging to reduce noise during execution\n- **Data Validation**: Checks for empty datasets and provides meaningful error messages\n\n## External Dependencies\n\n### Data Providers\n- **Yahoo Finance API**: Primary data source for historical stock prices via yfinance library\n- **Real-time Market Data**: Fetches OHLC (Open, High, Low, Close) data with configurable date ranges\n\n### Machine Learning Framework\n- **TensorFlow/Keras**: Core deep learning framework for model architecture and training\n- **Scikit-learn**: Provides preprocessing utilities (MinMaxScaler) and evaluation metrics\n\n### Data Processing and Visualization\n- **Pandas**: Primary data manipulation and analysis library for handling time series data\n- **NumPy**: Numerical computing foundation for array operations and mathematical functions\n- **Matplotlib**: Visualization library for plotting stock price trends and model performance\n\n### Development Tools\n- **Python Standard Library**: Uses os module for system operations and warnings for output control\n- **Jupyter Notebook Compatible**: Designed to work in interactive Python environments","size_bytes":3538},"stock_forecasting.py":{"content":"\"\"\"\nStock Price Forecasting using Hybrid CNN + BiLSTM + GRU Model\nThis script implements a comprehensive deep learning approach for predicting AAPL stock prices.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport yfinance as yf\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, GRU, Dense, Dropout\nimport warnings\nimport os\n\n# Suppress warnings for cleaner output\nwarnings.filterwarnings('ignore')\ntf.get_logger().setLevel('ERROR')\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\ndef load_data(ticker=\"AAPL\", start=\"2018-01-01\", end=\"2023-01-01\"):\n    \"\"\"\n    Load stock data from Yahoo Finance\n    \n    Args:\n        ticker (str): Stock ticker symbol\n        start (str): Start date in YYYY-MM-DD format\n        end (str): End date in YYYY-MM-DD format\n    \n    Returns:\n        pd.DataFrame: Stock data with Close prices\n    \"\"\"\n    try:\n        print(f\"Fetching {ticker} stock data from {start} to {end}...\")\n        data = yf.download(ticker, start=start, end=end, progress=False)\n        \n        if data.empty:\n            raise ValueError(f\"No data found for ticker {ticker}\")\n        \n        # Use only the Close column\n        close_data = data[['Close']].copy()\n        print(f\"Successfully loaded {len(close_data)} data points\")\n        \n        return close_data\n    \n    except Exception as e:\n        print(f\"Error loading data: {str(e)}\")\n        raise\n\ndef preprocess_data(data, window_size=60, test_split=0.2):\n    \"\"\"\n    Preprocess the stock data for training\n    \n    Args:\n        data (pd.DataFrame): Raw stock data\n        window_size (int): Number of timesteps to look back\n        test_split (float): Fraction of data for testing\n    \n    Returns:\n        tuple: X_train, X_test, y_train, y_test, scaler\n    \"\"\"\n    print(\"Preprocessing data...\")\n    \n    # Normalize the data\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    scaled_data = scaler.fit_transform(data.values)\n    \n    # Create sliding windows\n    X, y = [], []\n    \n    for i in range(window_size, len(scaled_data)):\n        X.append(scaled_data[i-window_size:i, 0])\n        y.append(scaled_data[i, 0])\n    \n    X, y = np.array(X), np.array(y)\n    \n    # Reshape for CNN input (samples, timesteps, features)\n    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n    \n    # Split into training and testing sets\n    split_idx = int(len(X) * (1 - test_split))\n    \n    X_train = X[:split_idx]\n    X_test = X[split_idx:]\n    y_train = y[:split_idx]\n    y_test = y[split_idx:]\n    \n    print(f\"Training samples: {X_train.shape[0]}\")\n    print(f\"Testing samples: {X_test.shape[0]}\")\n    print(f\"Input shape: {X_train.shape[1:]}\")\n    \n    return X_train, X_test, y_train, y_test, scaler\n\ndef build_model(input_shape=(60, 1)):\n    \"\"\"\n    Build the hybrid CNN + BiLSTM + GRU model\n    \n    Args:\n        input_shape (tuple): Shape of input data\n    \n    Returns:\n        tensorflow.keras.Model: Compiled model\n    \"\"\"\n    print(\"Building hybrid CNN + BiLSTM + GRU model...\")\n    \n    model = Sequential([\n        # CNN layer for feature extraction\n        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n        \n        # First BiLSTM layer with return sequences\n        Bidirectional(LSTM(64, return_sequences=True)),\n        Dropout(0.2),\n        \n        # Second BiLSTM layer with return sequences\n        Bidirectional(LSTM(64, return_sequences=True)),\n        Dropout(0.2),\n        \n        # First GRU layer with return sequences\n        GRU(64, return_sequences=True),\n        Dropout(0.2),\n        \n        # Second GRU layer without return sequences\n        GRU(64),\n        Dropout(0.2),\n        \n        # Dense layers for final prediction\n        Dense(50, activation='relu'),\n        Dense(1)\n    ])\n    \n    # Compile the model\n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    \n    print(\"Model architecture:\")\n    model.summary()\n    \n    return model\n\ndef train_and_evaluate(model, X_train, X_test, y_train, y_test, scaler):\n    \"\"\"\n    Train the model and evaluate its performance\n    \n    Args:\n        model: Compiled Keras model\n        X_train, X_test, y_train, y_test: Training and testing data\n        scaler: MinMaxScaler used for data normalization\n    \n    Returns:\n        tuple: (predictions, actual_values, rmse, mae)\n    \"\"\"\n    print(\"Training the model...\")\n    \n    # Train the model\n    history = model.fit(\n        X_train, y_train,\n        epochs=20,\n        batch_size=32,\n        validation_split=0.1,\n        verbose=1,\n        shuffle=False  # Important for time series data\n    )\n    \n    print(\"\\nEvaluating the model...\")\n    \n    # Make predictions\n    train_predictions = model.predict(X_train, verbose=0)\n    test_predictions = model.predict(X_test, verbose=0)\n    \n    # Inverse transform predictions and actual values\n    train_predictions = scaler.inverse_transform(train_predictions)\n    test_predictions = scaler.inverse_transform(test_predictions)\n    y_train_actual = scaler.inverse_transform(y_train.reshape(-1, 1))\n    y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n    \n    # Calculate metrics\n    train_rmse = np.sqrt(mean_squared_error(y_train_actual, train_predictions))\n    test_rmse = np.sqrt(mean_squared_error(y_test_actual, test_predictions))\n    train_mae = mean_absolute_error(y_train_actual, train_predictions)\n    test_mae = mean_absolute_error(y_test_actual, test_predictions)\n    \n    print(f\"\\nModel Performance:\")\n    print(f\"Training RMSE: ${train_rmse:.2f}\")\n    print(f\"Testing RMSE: ${test_rmse:.2f}\")\n    print(f\"Training MAE: ${train_mae:.2f}\")\n    print(f\"Testing MAE: ${test_mae:.2f}\")\n    \n    return test_predictions.flatten(), y_test_actual.flatten(), test_rmse, test_mae, history\n\ndef plot_results(actual, predicted, title=\"AAPL Stock Price Prediction\"):\n    \"\"\"\n    Plot actual vs predicted stock prices\n    \n    Args:\n        actual (array): Actual stock prices\n        predicted (array): Predicted stock prices\n        title (str): Plot title\n    \"\"\"\n    plt.figure(figsize=(12, 6))\n    \n    # Plot actual vs predicted\n    plt.plot(actual, label='Actual Price', color='blue', linewidth=2)\n    plt.plot(predicted, label='Predicted Price', color='red', linewidth=2)\n    \n    plt.title(title, fontsize=16, fontweight='bold')\n    plt.xlabel('Time (Days)', fontsize=12)\n    plt.ylabel('Stock Price ($)', fontsize=12)\n    plt.legend(fontsize=12)\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    \n    # Show the plot\n    plt.show()\n    \n    # Also save the plot\n    plt.savefig('stock_prediction_plot.png', dpi=300, bbox_inches='tight')\n    print(\"Plot saved as 'stock_prediction_plot.png'\")\n\ndef plot_training_history(history):\n    \"\"\"\n    Plot training history (loss and validation loss)\n    \n    Args:\n        history: Keras training history object\n    \"\"\"\n    plt.figure(figsize=(12, 4))\n    \n    # Plot training & validation loss\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    # Plot training & validation MAE\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['mae'], label='Training MAE')\n    plt.plot(history.history['val_mae'], label='Validation MAE')\n    plt.title('Model MAE')\n    plt.xlabel('Epoch')\n    plt.ylabel('Mean Absolute Error')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n    print(\"Training history plot saved as 'training_history.png'\")\n\ndef main():\n    \"\"\"\n    Main function to run the complete stock forecasting pipeline\n    \"\"\"\n    print(\"=\" * 60)\n    print(\"AAPL Stock Price Forecasting with Hybrid Deep Learning Model\")\n    print(\"=\" * 60)\n    \n    try:\n        # Step 1: Load data\n        stock_data = load_data()\n        \n        # Step 2: Preprocess data\n        X_train, X_test, y_train, y_test, scaler = preprocess_data(stock_data)\n        \n        # Step 3: Build model\n        model = build_model(input_shape=(60, 1))\n        \n        # Step 4: Train and evaluate\n        predictions, actual, rmse, mae, history = train_and_evaluate(\n            model, X_train, X_test, y_train, y_test, scaler\n        )\n        \n        # Step 5: Plot results\n        plot_results(actual, predictions)\n        plot_training_history(history)\n        \n        # Step 6: Print final summary\n        print(\"\\n\" + \"=\" * 60)\n        print(\"FINAL RESULTS SUMMARY\")\n        print(\"=\" * 60)\n        print(f\"Test Set RMSE: ${rmse:.2f}\")\n        print(f\"Test Set MAE: ${mae:.2f}\")\n        print(f\"Average actual price: ${np.mean(actual):.2f}\")\n        print(f\"Average predicted price: ${np.mean(predictions):.2f}\")\n        print(f\"Prediction accuracy: {100 - (mae/np.mean(actual)*100):.2f}%\")\n        print(\"=\" * 60)\n        \n        # Optional: Save the model\n        model.save('stock_forecasting_model.h5')\n        print(\"Model saved as 'stock_forecasting_model.h5'\")\n        \n    except Exception as e:\n        print(f\"An error occurred: {str(e)}\")\n        print(\"Please check your internet connection and try again.\")\n        return False\n    \n    return True\n\nif __name__ == \"__main__\":\n    # Check if required packages are available\n    required_packages = ['pandas', 'numpy', 'matplotlib', 'sklearn', 'yfinance', 'tensorflow']\n    missing_packages = []\n    \n    for package in required_packages:\n        try:\n            __import__(package)\n        except ImportError:\n            missing_packages.append(package)\n    \n    if missing_packages:\n        print(\"Missing required packages:\")\n        for pkg in missing_packages:\n            print(f\"  - {pkg}\")\n        print(\"\\nPlease install missing packages using:\")\n        print(f\"pip install {' '.join(missing_packages)}\")\n    else:\n        # Run the main function\n        success = main()\n        \n        if success:\n            print(\"\\nStock forecasting script completed successfully!\")\n        else:\n            print(\"\\nScript execution failed. Please check the error messages above.\")\n","size_bytes":10426}},"version":1}